@misc{zhao2024tscliprobustclipfinetuning,
      title={TSCLIP: Robust CLIP Fine-Tuning for Worldwide Cross-Regional Traffic Sign Recognition}, 
      author={Guoyang Zhao and Fulong Ma and Weiqing Qi and Chenguang Zhang and Yuxuan Liu and Ming Liu and Jun Ma},
      year={2024},
      eprint={2409.15077},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.15077}, 
}

@misc{radford2021learningtransferablevisualmodels,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2103.00020}, 
}

@article{STALLKAMP2012323,
title = {Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition},
journal = {Neural Networks},
volume = {32},
pages = {323-332},
year = {2012},
note = {Selected Papers from IJCNN 2011},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2012.02.016},
url = {https://www.sciencedirect.com/science/article/pii/S0893608012000457},
author = {J. Stallkamp and M. Schlipsing and J. Salmen and C. Igel},
keywords = {Traffic sign recognition, Machine learning, Convolutional neural networks, Benchmarking},
abstract = {Traffic signs are characterized by a wide variability in their visual appearance in real-world environments. For example, changes of illumination, varying weather conditions and partial occlusions impact the perception of road signs. In practice, a large number of different sign classes needs to be recognized with very high accuracy. Traffic signs have been designed to be easily readable for humans, who perform very well at this task. For computer systems, however, classifying traffic signs still seems to pose a challenging pattern recognition problem. Both image processing and machine learning algorithms are continuously refined to improve on this task. But little systematic comparison of such systems exist. What is the status quo? Do today’s algorithms reach human performance? For assessing the performance of state-of-the-art machine learning algorithms, we present a publicly available traffic sign dataset with more than 50,000 images of German road signs in 43 classes. The data was considered in the second stage of the German Traffic Sign Recognition Benchmark held at IJCNN 2011. The results of this competition are reported and the best-performing algorithms are briefly described. Convolutional neural networks (CNNs) showed particularly high classification accuracies in the competition. We measured the performance of human subjects on the same data—and the CNNs outperformed the human test persons.}
}

@misc{GoogleColab, 
      url={https://colab.research.google.com/}, 
      journal={Google Colaboratory}, 
      author={Google}, 
      publisher={Google}
}

@misc{goyal2022finetunelikepretrainimproved,
      title={Finetune like you pretrain: Improved finetuning of zero-shot vision models}, 
      author={Sachin Goyal and Ananya Kumar and Sankalp Garg and Zico Kolter and Aditi Raghunathan},
      year={2022},
      eprint={2212.00638},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2212.00638}, 
}

@misc{loshchilov2019decoupledweightdecayregularization,
      title={Decoupled Weight Decay Regularization}, 
      author={Ilya Loshchilov and Frank Hutter},
      year={2019},
      eprint={1711.05101},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1711.05101}, 
}

@article{arcos2018deep,
  title={Deep neural network for traffic sign recognition systems: An analysis of spatial transformers and stochastic optimisation methods},
  author={Arcos-Garc{\'\i}a, {\'A}lvaro and Alvarez-Garcia, Juan A and Soria-Morillo, Luis M},
  journal={Neural Networks},
  volume={99},
  pages={158--165},
  year={2018},
  publisher={Elsevier}
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMJUDogh19IHybIICv/acqh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matteomrz/20242R0136COSE47402/blob/main/final/final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mwhNL4nQgNx",
        "outputId": "fc8b40d4-19d3-403e-e848-92bf30e133b1",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-clip in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from openai-clip) (6.3.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from openai-clip) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-clip) (4.66.6)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->openai-clip) (0.2.13)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai-clip\n",
        "!pip install datasets\n",
        "!pip install torch\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "ds = load_dataset(\"bazyl/GTSRB\")\n",
        "\n",
        "train_full = ds['train']\n",
        "\n",
        "# Map used Street Sign IDs to text descriptions\n",
        "id_to_description = {\n",
        "    18: \"General caution\",\n",
        "    19: \"Dangerous curve left\",\n",
        "    20: \"Dangerous curve right\",\n",
        "    21: \"Winding road\",\n",
        "    22: \"Bumpy road\",\n",
        "    23: \"Slippery road\",\n",
        "    24: \"Road narrows on the right\",\n",
        "    25: \"Road work\",\n",
        "    26: \"Traffic lights\",\n",
        "    27: \"Pedestrians\",\n",
        "    28: \"Children crossing\",\n",
        "    29: \"Bike crossing\",\n",
        "    30: \"Beware of ice/snow\",\n",
        "    31: \"Wild animals crossing\",\n",
        "}\n",
        "\n",
        "# Filter for warning signs\n",
        "train_full = [example for example in train_full if example['ClassId'] in id_to_description]\n",
        "\n",
        "# Replace ClassId with Text Description\n",
        "for instance in train_full:\n",
        "    instance['Description'] = id_to_description[instance['ClassId']]\n",
        "\n",
        "len_train = int(0.8 * len(train_full))\n",
        "train, val = random_split(train_full, [len_train, len(train_full) - len_train])"
      ],
      "metadata": {
        "id": "sh7PWl3KQmcQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "7a81341e-46c2-449c-e849-f5ea8e52bf9f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import clip\n",
        "import torch\n",
        "\n",
        "model, preprocess = clip.load(\"ViT-B/32\", jit=False)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lujhaRVXEKG",
        "outputId": "4676329d-563a-4931-ba66-9990930151b4",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CLIP(\n",
              "  (visual): VisionTransformer(\n",
              "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
              "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (transformer): Transformer(\n",
              "      (resblocks): Sequential(\n",
              "        (0): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (6): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (7): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (8): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (9): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (10): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (11): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (transformer): Transformer(\n",
              "    (resblocks): Sequential(\n",
              "      (0): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (1): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (2): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (3): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (4): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (5): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (6): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (7): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (8): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (9): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (10): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (11): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (token_embedding): Embedding(49408, 512)\n",
              "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "JzF4V_71W0PR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class WarningSignDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        image = Image.open(BytesIO(item['Path']['bytes']))\n",
        "        return self.transform(image), item['ClassId'] - 18\n",
        "\n",
        "        # returns the number of the fucking description"
      ],
      "metadata": {
        "id": "6JOMEw9huWfC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "train_loader = DataLoader(WarningSignDataset(train), batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(WarningSignDataset(val), batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "5G7LKVcU279z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Modify the model to include a classifier for subcategories\n",
        "class CLIPFineTuner(nn.Module):\n",
        "    def __init__(self, model, num_classes):\n",
        "        super(CLIPFineTuner, self).__init__()\n",
        "        self.model = model\n",
        "        self.classifier = nn.Linear(model.visual.output_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        with torch.no_grad():\n",
        "            features = self.model.encode_image(x).float()  # Convert to float32\n",
        "        return self.classifier(features)"
      ],
      "metadata": {
        "id": "6nqiN0KQ3CuX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(id_to_description)\n",
        "model_ft = CLIPFineTuner(model, num_classes).to(device)"
      ],
      "metadata": {
        "id": "JLiM8Tgx3Dfh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_ft.classifier.parameters(), lr=5e-4)\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "OT9WnAI03NYT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Number of epochs for training\n",
        "num_epochs = 20\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model_ft.train()  # Set the model to training mode\n",
        "    running_loss = 0.0  # Initialize running loss for the current epoch\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}, Loss: 0.0000\")  # Initialize progress bar\n",
        "\n",
        "    for images, labels in pbar:\n",
        "        images, labels = images.to(device), labels.to(device)  # Move images and labels to the device (GPU or CPU)\n",
        "        optimizer.zero_grad()  # Clear the gradients of all optimized variables\n",
        "        outputs = model_ft(images)  # Forward pass: compute predicted outputs by passing inputs to the model\n",
        "        loss = criterion(outputs, labels)  # Calculate the loss\n",
        "        loss.backward()  # Backward pass: compute gradient of the loss with respect to model parameters\n",
        "        optimizer.step()  # Perform a single optimization step (parameter update)\n",
        "\n",
        "        running_loss += loss.item()  # Update running loss\n",
        "        pbar.set_description(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")  # Update progress bar with current loss\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')  # Print average loss for the epoch\n",
        "\n",
        "    scheduler.step()  # Update learning rate scheduler\n",
        "\n",
        "    # Validation\n",
        "    model_ft.eval()  # Set the model to evaluation mode\n",
        "    correct = 0  # Initialize correct predictions counter\n",
        "    total = 0  # Initialize total samples counter\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for validation\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)  # Move images and labels to the device\n",
        "            outputs = model_ft(images)  # Forward pass: compute predicted outputs by passing inputs to the model\n",
        "            _, predicted = torch.max(outputs.data, 1)  # Get the class label with the highest probability\n",
        "            total += labels.size(0)  # Update total samples\n",
        "            correct += (predicted == labels).sum().item()  # Update correct predictions\n",
        "\n",
        "    print(f'Validation Accuracy: {100 * correct / total}%')  # Print validation accuracy for the epoch\n",
        "\n",
        "# Save the fine-tuned model\n",
        "torch.save(model_ft.state_dict(), 'clip_finetuned.pth')  # Save the model's state dictionary\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGpXEKzK3fCD",
        "outputId": "9bc13f18-4c4b-4532-f0e8-ef8408016210"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20, Loss: 2.1131: 100%|██████████| 192/192 [00:18<00:00, 10.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 2.1131\n",
            "Validation Accuracy: 50.78431372549019%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/20, Loss: 1.5761: 100%|██████████| 192/192 [00:18<00:00, 10.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/20], Loss: 1.5761\n",
            "Validation Accuracy: 66.40522875816994%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/20, Loss: 1.2589: 100%|██████████| 192/192 [00:18<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/20], Loss: 1.2589\n",
            "Validation Accuracy: 73.20261437908496%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/20, Loss: 1.0587: 100%|██████████| 192/192 [00:18<00:00, 10.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/20], Loss: 1.0587\n",
            "Validation Accuracy: 77.51633986928104%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/20, Loss: 0.9193: 100%|██████████| 192/192 [00:18<00:00, 10.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/20], Loss: 0.9193\n",
            "Validation Accuracy: 81.17647058823529%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/20, Loss: 0.8150: 100%|██████████| 192/192 [00:18<00:00, 10.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/20], Loss: 0.8150\n",
            "Validation Accuracy: 83.39869281045752%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/20, Loss: 0.7352: 100%|██████████| 192/192 [00:18<00:00, 10.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/20], Loss: 0.7352\n",
            "Validation Accuracy: 84.37908496732027%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/20, Loss: 0.6715: 100%|██████████| 192/192 [00:18<00:00, 10.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/20], Loss: 0.6715\n",
            "Validation Accuracy: 85.49019607843137%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/20, Loss: 0.6171: 100%|██████████| 192/192 [00:17<00:00, 10.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/20], Loss: 0.6171\n",
            "Validation Accuracy: 87.58169934640523%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/20, Loss: 0.5721: 100%|██████████| 192/192 [00:18<00:00, 10.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/20], Loss: 0.5721\n",
            "Validation Accuracy: 87.7124183006536%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/20, Loss: 0.5475: 100%|██████████| 192/192 [00:19<00:00,  9.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/20], Loss: 0.5475\n",
            "Validation Accuracy: 88.16993464052288%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/20, Loss: 0.5410: 100%|██████████| 192/192 [00:18<00:00, 10.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/20], Loss: 0.5410\n",
            "Validation Accuracy: 88.16993464052288%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/20, Loss: 0.5364: 100%|██████████| 192/192 [00:17<00:00, 10.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/20], Loss: 0.5364\n",
            "Validation Accuracy: 88.16993464052288%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/20, Loss: 0.5323: 100%|██████████| 192/192 [00:18<00:00, 10.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/20], Loss: 0.5323\n",
            "Validation Accuracy: 88.30065359477125%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/20, Loss: 0.5281: 100%|██████████| 192/192 [00:18<00:00, 10.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/20], Loss: 0.5281\n",
            "Validation Accuracy: 88.23529411764706%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/20, Loss: 0.5260: 100%|██████████| 192/192 [00:18<00:00, 10.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/20], Loss: 0.5260\n",
            "Validation Accuracy: 88.36601307189542%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/20, Loss: 0.5215: 100%|██████████| 192/192 [00:17<00:00, 10.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/20], Loss: 0.5215\n",
            "Validation Accuracy: 88.49673202614379%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/20, Loss: 0.5170: 100%|██████████| 192/192 [00:17<00:00, 10.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/20], Loss: 0.5170\n",
            "Validation Accuracy: 88.49673202614379%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/20, Loss: 0.5135: 100%|██████████| 192/192 [00:18<00:00, 10.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/20], Loss: 0.5135\n",
            "Validation Accuracy: 88.69281045751634%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/20, Loss: 0.5090: 100%|██████████| 192/192 [00:18<00:00, 10.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/20], Loss: 0.5090\n",
            "Validation Accuracy: 88.69281045751634%\n"
          ]
        }
      ]
    }
  ]
}